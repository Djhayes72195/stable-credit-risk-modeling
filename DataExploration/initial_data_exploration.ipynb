{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/dustinhayes/Desktop/GitHub/stable-credit-risk-modeling/\")\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from DataProcessing.pipeline import Pipeline\n",
    "\n",
    "\n",
    "ROOT = Path('/Users/dustinhayes/Desktop/GitHub/stable-credit-risk-modeling/Data')\n",
    "TRAIN_DIR = ROOT / \"original_parquet_files\" / \"train\"\n",
    "TEST_DIR = ROOT / \"original_parquet_files\" / \"test\"\n",
    "FEATURE_DEFINITIONS = ROOT / \"feature_definitions.csv\"\n",
    "LOG_PATH = Path(\"/Users/dustinhayes/Desktop/GitHub/stable-credit-risk-modeling/Logs\")\n",
    "NUM_GROUPS = {\"num_group1\": \"Depth 1 index\", \"num_group2\": \"Depth 2 index\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory:  /Users/dustinhayes/Desktop/GitHub/stable-credit-risk-modeling/DataExploration\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have access to a csv which contains definitions for each feature. It would be nice to be able to print out a df and anutomatically retreive information on each column. I'll write a quick function to do that.\n",
    "\n",
    "I'll also write a quick function to write a polars df to my clipboard so that I can inspect it in excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_def_df = pd.read_csv(FEATURE_DEFINITIONS)\n",
    "SEPERATOR = \"===============================================================================\"\n",
    "\n",
    "def print_df_and_define_columns(df):\n",
    "    log_path = LOG_PATH / \"print_df_and_define_columns.txt\"\n",
    "    cols = df.columns\n",
    "    col_defs = feature_def_df[feature_def_df['Variable'].isin(cols)]\n",
    "    with open(log_path, 'w') as f:\n",
    "        for index, row in col_defs.iterrows():\n",
    "            variable = row.Variable\n",
    "            description = row.Description\n",
    "            msg = f\"{variable}: {description}\"\n",
    "            print(msg)\n",
    "            f.write(msg + \"\\n\")\n",
    "            print(SEPERATOR)\n",
    "    print(df)\n",
    "\n",
    "\n",
    "def to_clipboard(df, top_rows=10):\n",
    "    df = df.to_pandas()\n",
    "    df = df.head(top_rows)\n",
    "    df.to_clipboard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should take some time to explore some depth 1 and depth 2 tables to speculate on appropriate methods of aggregation.\n",
    "\n",
    "Let's take example depth 1 table \"train_tax_registry_a_1.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "amount_4527230A: Tax deductions amount tracked by the government registry.\n",
      "===============================================================================\n",
      "name_4527232M: Name of employer.\n",
      "===============================================================================\n",
      "recorddate_4527225D: Date of tax deduction record.\n",
      "===============================================================================\n",
      "shape: (3_275_770, 5)\n",
      "┌─────────┬─────────────────┬───────────────┬────────────┬─────────────────────┐\n",
      "│ case_id ┆ amount_4527230A ┆ name_4527232M ┆ num_group1 ┆ recorddate_4527225D │\n",
      "│ ---     ┆ ---             ┆ ---           ┆ ---        ┆ ---                 │\n",
      "│ i64     ┆ f64             ┆ str           ┆ i64        ┆ str                 │\n",
      "╞═════════╪═════════════════╪═══════════════╪════════════╪═════════════════════╡\n",
      "│ 28631   ┆ 711.0           ┆ f980a1ea      ┆ 3          ┆ 2019-09-13          │\n",
      "│ 28631   ┆ 1946.0          ┆ f980a1ea      ┆ 2          ┆ 2019-09-13          │\n",
      "│ 28631   ┆ 2600.0          ┆ f980a1ea      ┆ 1          ┆ 2019-09-13          │\n",
      "│ 28631   ┆ 3616.4001       ┆ f980a1ea      ┆ 0          ┆ 2019-09-13          │\n",
      "│ 28632   ┆ 400.0           ┆ 5f9b74f5      ┆ 6          ┆ 2019-09-13          │\n",
      "│ …       ┆ …               ┆ …             ┆ …          ┆ …                   │\n",
      "│ 2701515 ┆ 2992.0          ┆ 48e44a99      ┆ 0          ┆ 2020-10-09          │\n",
      "│ 2701515 ┆ 4691.8003       ┆ 5e180ef0      ┆ 1          ┆ 2020-10-09          │\n",
      "│ 2702290 ┆ 850.0           ┆ 94721311      ┆ 0          ┆ 2020-10-13          │\n",
      "│ 2702290 ┆ 850.0           ┆ 94721311      ┆ 1          ┆ 2020-10-13          │\n",
      "│ 2702290 ┆ 850.0           ┆ 94721311      ┆ 2          ┆ 2020-10-13          │\n",
      "└─────────┴─────────────────┴───────────────┴────────────┴─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "tax_registry_a_1_path = TRAIN_DIR / \"train_tax_registry_a_1.parquet\"\n",
    "tax_reg_a1_df = pl.read_parquet(tax_registry_a_1_path)\n",
    "print_df_and_define_columns(tax_reg_a1_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that in train_tax_registry_a_1.parquet we have 5 columns: case_id, amount_4527230A, name_4527232M, num_group1, recorddate_4527225D, with descriptions: \n",
    "\n",
    "===============================================================================\n",
    "amount_4527230A: Tax deductions amount tracked by the government registry.\n",
    "===============================================================================\n",
    "name_4527232M: Name of employer.\n",
    "===============================================================================\n",
    "recorddate_4527225D: Date of tax deduction record.\n",
    "===============================================================================\n",
    "\n",
    "The precise meaning of num_group1, and num_group2 were not immediately clear to me. A post by the competition host helped:\n",
    "\n",
    "Hi,\n",
    "okay, let me explain on hypothetical example:\n",
    "\n",
    "Tomas Jelinek applied for loan on 1.1.2024 - this is credit case, which has assigned unique case_id\n",
    "Tomas Jelinek is existing client in Home Credit, it means he had applications/loans with Home Credit before 1.1.2024, let's say 5 loans. Data describing parameters of those loans, their repayment history etc. are definitely valuable for credit scoring, therefore you have them in the sample. But they are not aggregated on level of case_id, there are 5 rows describing those 5 previous loans. To differentiate between those 5, you have to have some index - num_group_1, which will contain values 0,1,2,3,4…\n",
    "num_group_1 is not used only for previous applications, but for other data where we have several records per case_id, like contact references, records in credit registry, etc. What I want to say is there is different meaning for different tables & attributes\n",
    "is some cases we might have even bigger detail, for example information about instalments for each previous application. Then you need num_group_2, for example let's say previous loan with num_group_1=0 have 3 instalments, then you will have 3 records with num_group_1 = 0 and num_group_2 = 0,1,2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a depth 2 table as well. I have chosen credit_bureau_b_2_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_group1:  Depth 1 index.\n",
      "===============================================================================\n",
      "num_group2:  Depth 2 index.\n",
      "===============================================================================\n",
      "pmts_date_1107D: Payment date for an active contract according to credit bureau (num_group1 - contract, num_group2 - payment).\n",
      "===============================================================================\n",
      "pmts_dpdvalue_108P: Value of past due payment for active contract (num_group1 - existing contract, num_group2 - payment).\n",
      "===============================================================================\n",
      "pmts_pmtsoverdue_635A: Active contract that has overdue payments (num_group1 - existing contract, num_group2 - payment).\n",
      "===============================================================================\n",
      "shape: (1_286_755, 6)\n",
      "┌─────────┬────────────┬────────────┬─────────────────┬────────────────────┬───────────────────────┐\n",
      "│ case_id ┆ num_group1 ┆ num_group2 ┆ pmts_date_1107D ┆ pmts_dpdvalue_108P ┆ pmts_pmtsoverdue_635A │\n",
      "│ ---     ┆ ---        ┆ ---        ┆ ---             ┆ ---                ┆ ---                   │\n",
      "│ i64     ┆ i64        ┆ i64        ┆ str             ┆ f64                ┆ f64                   │\n",
      "╞═════════╪════════════╪════════════╪═════════════════╪════════════════════╪═══════════════════════╡\n",
      "│ 467     ┆ 0          ┆ 0          ┆ 2018-11-15      ┆ null               ┆ null                  │\n",
      "│ 467     ┆ 0          ┆ 1          ┆ 2018-12-15      ┆ null               ┆ null                  │\n",
      "│ 467     ┆ 1          ┆ 0          ┆ 2018-12-15      ┆ null               ┆ null                  │\n",
      "│ 467     ┆ 2          ┆ 0          ┆ 2016-10-15      ┆ 0.0                ┆ 0.0                   │\n",
      "│ 467     ┆ 2          ┆ 1          ┆ 2016-11-15      ┆ 0.0                ┆ 0.0                   │\n",
      "│ …       ┆ …          ┆ …          ┆ …               ┆ …                  ┆ …                     │\n",
      "│ 2703436 ┆ 1          ┆ 31         ┆ 2020-05-15      ┆ 0.0                ┆ 0.0                   │\n",
      "│ 2703436 ┆ 1          ┆ 32         ┆ 2020-06-15      ┆ 0.0                ┆ 0.0                   │\n",
      "│ 2703436 ┆ 1          ┆ 33         ┆ 2020-07-15      ┆ 0.0                ┆ 0.0                   │\n",
      "│ 2703436 ┆ 1          ┆ 34         ┆ 2020-08-15      ┆ 0.0                ┆ 0.0                   │\n",
      "│ 2703436 ┆ 1          ┆ 35         ┆ 2020-09-15      ┆ 0.0                ┆ 0.0                   │\n",
      "└─────────┴────────────┴────────────┴─────────────────┴────────────────────┴───────────────────────┘\n",
      "Range of the pmts_pmtsoverdue_635A: 147470.61\n"
     ]
    }
   ],
   "source": [
    "credit_bureau_b_2_path = TRAIN_DIR / \"train_credit_bureau_b_2.parquet\"\n",
    "print_df_and_define_columns(pl.read_parquet(credit_bureau_b_2_path))\n",
    "\n",
    "\n",
    "credit_bureau_b_2_df = pl.read_parquet(credit_bureau_b_2_path).fill_null(0.0)\n",
    "filter_case_id = credit_bureau_b_2_df.filter((pl.col('pmts_dpdvalue_108P') > 0) & (pl.col(\"pmts_pmtsoverdue_635A\") > 0)) # Filter to one id for readability\n",
    "# print_df_and_define_columns(filter_case_id)\n",
    "max_value = credit_bureau_b_2_df.select(pl.max('pmts_pmtsoverdue_635A')).to_numpy()[0, 0]\n",
    "min_value = credit_bureau_b_2_df.select(pl.min('pmts_pmtsoverdue_635A')).to_numpy()[0, 0]\n",
    "column_range = max_value - min_value\n",
    "\n",
    "print(\"Range of the pmts_pmtsoverdue_635A:\", column_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are five columns: case_id, num_group1, num_group2, pmts_date_1107D, pmts_dpdvalue_108P, and pmts_pmtsoverdue_635A.\n",
    "\n",
    "This is a depth two table. The first layer of depth is existing contract. A single case_id may have multiple contracts in repayment. These multiple contracts are enumerated with num_group1. Within a single contract, multiple payments are recorded. pmts_date_1107D, pmts_dpdvalue_108P, and pmts_pmtsoverdue_635A representing payment date, value of past due contract, and active contract that has overdue payments are recorded at the payment level, enumerated with num_group2.\n",
    "\n",
    "I am still a little confused as to the precise meaning of pmts_dpdvalue_108P, and pmts_pmtsoverdue_635A.\n",
    "\n",
    "===============================================================================\n",
    "pmts_dpdvalue_108P: Value of past due payment for active contract (num_group1 - existing contract, num_group2 - payment).\n",
    "===============================================================================\n",
    "\n",
    "Is this the amount of money that was paid past due, or is it the amount past due that remains after the payment?\n",
    "\n",
    "P - Transform DPD (Days past due) - Float\n",
    "\n",
    "But it says \"Value\", not # of days past due or anything of the sort.\n",
    "\n",
    "Notably\n",
    "\n",
    "\n",
    "===============================================================================\n",
    "pmts_pmtsoverdue_635A: Active contract that has overdue payments (num_group1 - existing contract, num_group2 - payment).\n",
    "===============================================================================\n",
    "\n",
    "These are numerical values that do not seem to specify which contract is overdue. Is this how much is left past due after the payment?\n",
    "\n",
    "I'll investigate a bit further..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_bureau_b_2_path = TRAIN_DIR / \"train_credit_bureau_b_2.parquet\"\n",
    "\n",
    "credit_bureau_b_2_df = pl.read_parquet(credit_bureau_b_2_path).fill_null(0.0)\n",
    "pmts_dpdvalue_108P = credit_bureau_b_2_df.get_column('pmts_dpdvalue_108P').to_numpy()\n",
    "pmts_dpdvalue_108P = pmts_dpdvalue_108P[pmts_dpdvalue_108P != 0.0] # I'm interested in observing overdue payments\n",
    "pmts_pmtsoverdue_635A = credit_bureau_b_2_df.get_column('pmts_pmtsoverdue_635A').to_numpy()\n",
    "pmts_pmtsoverdue_635A = pmts_pmtsoverdue_635A[pmts_pmtsoverdue_635A != 0.0]\n",
    "\n",
    "num_bins = 15\n",
    "\n",
    "hist_pmts_dpdvalue_108P, bin_edges_pmts_dpdvalue_108P = np.histogram(pmts_dpdvalue_108P, bins=num_bins)\n",
    "hist_pmts_pmtsoverdue_635A, bin_edges_pmts_pmtsoverdue_635A = np.histogram(pmts_pmtsoverdue_635A, bins=num_bins)\n",
    "\n",
    "def plot_hist(hist_counts, bin_edges, feature):\n",
    "    plt.bar(bin_edges[:-1], hist_counts, width=np.diff(bin_edges), log=True, edgecolor='black', align='edge')\n",
    "    plt.title(f\"{feature}\")\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('log(Frequency)') # Plot log to see extreme values easier.\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(hist_pmts_dpdvalue_108P, bin_edges_pmts_dpdvalue_108P, \"pmts_dpdvalue_108P\")\n",
    "plot_hist(hist_pmts_pmtsoverdue_635A, bin_edges_pmts_pmtsoverdue_635A, \"pmts_pmtsoverdue_635A\")\n",
    "\n",
    "print(bin_edges_pmts_pmtsoverdue_635A)\n",
    "print(f\"Hist counts for pmts_pmtsoverdue_635A, in bins of around 10,000 {hist_pmts_pmtsoverdue_635A}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found some interesting hist counts for pmts_pmtsoverdue_635A. With bins of around 10,000, after filtering out zeros:\n",
    "\n",
    "[144472      0      0      0      0      0      0      0      0      0\n",
    "0      0      0      0     12]\n",
    "\n",
    "So almost everything is less than 10,000, but we have exactly 12 counts sitting around 140,000. What could this mean? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what the data looks like without these 12 very large values.\n",
    "non_outlier_pmts_pmtsoverdue_635A = np.sort(pmts_pmtsoverdue_635A)[:-12]\n",
    "print(f\"Mean of pmts_pmtsoverdue_635A w/o the 12 outliers: {np.mean(non_outlier_pmts_pmtsoverdue_635A)}\")\n",
    "\n",
    "\n",
    "hist_non_outlier_pmts_pmtsoverdue_635A, bin_edges_non_outlier_pmts_pmtsoverdue_635A = np.histogram(non_outlier_pmts_pmtsoverdue_635A, bins=num_bins)\n",
    "plot_hist(hist_non_outlier_pmts_pmtsoverdue_635A, bin_edges_non_outlier_pmts_pmtsoverdue_635A, \"non_outlier_pmts_pmtsoverdue_635A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the outliers we see a right-skewed distribution with a max value of around 1000. Although we still have not explained the outliers, I doubt that the units we are dealing with is USD.\n",
    "\n",
    "Notes on col dtype coding:\n",
    "\n",
    "        P - Transform DPD (Days past due) - Float\n",
    "        M - Masking categories - String\n",
    "        A - Transform amount - Float\n",
    "        D - Transform date - Date\n",
    "        T - Unspecified Transform - Not handled\n",
    "        L - Unspecified Transform - Not handled\n",
    "\n",
    "So far I have observed:\n",
    "         - mts_dpdvalue_108P:\n",
    "                - Always a whole number.\n",
    "                - Suffix \"P\" is supposed to mean it is days past due transformed, but that does not seems to align with its description: \"Value of past due payment for active contract (num_group1 - existing contract, num_group2 - payment)\"\n",
    "        - pmts_pmtsoverdue_635A:\n",
    "                - Is usually less than 1000, but there are 12 records with values around 140,000 with nothing in between.\n",
    "                - Is not always a whole number, but it a multiple of .2 for some reason\n",
    "        - One of these columns may be zero when the other is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_pmtsoverdue = credit_bureau_b_2_df.filter(pl.col(\"pmts_pmtsoverdue_635A\") > 10000)\n",
    "non_zero_pmtsoverdue = credit_bureau_b_2_df.filter(pl.col(\"pmts_pmtsoverdue_635A\") > 0.0)\n",
    "specific_case_id = credit_bureau_b_2_df.filter(pl.col(\"case_id\") == 1445)\n",
    "print(specific_case_id)\n",
    "\n",
    "# Is one always zero when the other is zero?\n",
    "# check_if_empty = credit_bureau_b_2_df.filter((pl.col(\"pmts_pmtsoverdue_635A\") == 0) & (pl.col(\"pmts_dpdvalue_108P\") != 0))\n",
    "# print(check_if_empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that I have chosen to investigate a table which has confused other kagglers as well. I found a thread which discusses exactly this, but offers no definitive conclusion: https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/discussion/478631\n",
    "\n",
    "I found another thread, https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/discussion/485634, where user aahhammer offers this explaination:\n",
    "\n",
    "\n",
    "- the num_group1 in credit_bureau_b_2 referes to the num_group1 in credit_bureau_b_1.\n",
    "- Its all client credits. In your case 1702371 the client has only two documented credits\n",
    "Look at e.g. case 1445 to see a different scenario with 0-4 in num_group1\n",
    "- the DPD value of 9186 is rather the monetary value which was paid late\n",
    "the 0.2 [in pmts_pmtsoverdue_635A] are rather the percentage of the total credit value. the total credit value is documented in credit_bureau_b_1 column amount_1115A with 43998.0. 9186 is about 20% of that value. I rather trust the data then the documentation here.\n",
    "\n",
    "I'm not quite convinced, though. If pmts_pmtsoverdue_635A represent percentage of total credit value, anything above 1.0 would not make sense. We regularly see values over 1.0, and the max of this column is 140,000. \n",
    "\n",
    "Let's bring in credit_bureau_b_1, which contains total credit value, and see if the aahhammer's hypothesis regarding pmts_pmtsoverdue_635A is justified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_bureau_b_1_path = TRAIN_DIR / \"train_credit_bureau_b_1.parquet\"\n",
    "credit_bureau_b_1_df = pl.read_parquet(credit_bureau_b_1_path)\n",
    "credit_bureau_b_2_df = pl.read_parquet(credit_bureau_b_2_path)\n",
    "\n",
    "print_df_and_define_columns(credit_bureau_b_1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_b_1_df = Pipeline.set_table_dtypes(credit_bureau_b_1_df) # Needed because case_id does not have the same dtype in the two tables for some reason.\n",
    "# print_df_and_define_columns(cb_b_1_df)\n",
    "cb_b_1_df = cb_b_1_df.select(['case_id', 'num_group1', 'amount_1115A'])\n",
    "cb_b_2_df = Pipeline.set_table_dtypes(credit_bureau_b_2_df)\n",
    "\n",
    "# Investigate single case\n",
    "cb_b_1_df = cb_b_1_df.filter(pl.col('case_id') == 1934)\n",
    "# print_df_and_define_columns(cb_b_1_df)\n",
    "cb_b_2_df = cb_b_2_df.filter(pl.col('case_id') == 1934)\n",
    "# print_df_and_define_columns(cb_b_2_df)\n",
    "\n",
    "\n",
    "cb_joined = cb_b_2_df.join(\n",
    "    cb_b_1_df,\n",
    "    on=['case_id', 'num_group1'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "to_clipboard(cb_joined, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aahhammer's hypoethesis checks out for 1702371: pmts_pmtsoverdue_635A is approximately the percentage of total credit paid off overdue. This theory does not check out for other case_ids, though. I remain unconvinced, but do not have an alternative explaination.\n",
    "\n",
    "Let's look at a thread that describes our data at a higher level: https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/discussion/473950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
